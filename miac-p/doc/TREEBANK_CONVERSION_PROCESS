************************************
Treebank Conversion Process Document
by Stephen Tratz

This document contains step-by-step instructions for converting the Penn Treebank 
	from constituent parses into dependency parses. The dependency scheme has changed since Tratz and Hovy's (2011) parser publication.

NOTE: The final script may perform strangely if functional tags and/or trace information isn't available in the original constituent parses.
************************************

=============================================
 STEP 1: Obtain the Penn Treebank version III
=============================================

The Penn Treebank is not free. Hopefully, you are affiliated with an organization that has access.

http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC99T42


=============================================
 STEP 2: Download Vadas and Curran's (2007) noun phrase structure patch
=============================================
Download link:
http://sydney.edu.au/engineering/it/~dvadas1/np_data/PTB_NP_Bracketing_Data_1.0.tgz


=============================================
 STEP 3: Apply Vadas and Curran's patch
=============================================
The command for running it is 'run_insert <source directory> <output directory>'
For example:
	./run_insert Treebank_3/parsed/mrg/wsj Treebank_3/parsed/mrg/wsjNNpatched

=============================================
 STEP 4: Combine the modified Treebank files together (not technically necessary)
=============================================
Here is a script that will take sections 2-23 and put 2-21 in a training file, 
	22 in a development file, and 23 in a test file

#!/bin/bash

#The patched Penn Treebank files
DATA_DIR="Treebank_3/parsed/mrg/wsjNNpatched"
#The depth of that directory from the current directory +1
DEPTH=../../../../..

#The output files
TRAINING_FILE=${DEPTH}/training.mrg
DEVELOPMENT_FILE=${DEPTH}/development.mrg
TEST_FILE=${DEPTH}/test.mrg

#The section to put in the development file
DEVELOPMENT_SECTION=22
#The section to put in the test file
TEST_SECTION=23
#The complete list of sections to extract
SECTIONS_TO_EXTRACT="02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23"
for i in $SECTIONS_TO_EXTRACT
do	
	cd ${DATA_DIR}/$i
	for f in *.mrg
	do
		echo $f
		if [ $i -eq ${DEVELOPMENT_SECTION} ]; then
			cat $f >> ${DEVELOPMENT_FILE}
		else
			if [ $i -eq ${TEST_SECTION} ]; then
				cat $f >> ${TEST_FILE}
			else
				cat $f >> ${TRAINING_FILE}
			fi
		fi
		
	done	
	cd ${DEPTH}
done
	
	
============================================
STEP 5: Run a modified version of the pennconverter tool
============================================

PENNCONVERTER_JAR=pennconverter_modified_Spring2012.jar
ARGS="-format=conllx  -splitSmallClauses=false -splitSlash=false -imAsHead=false  -ddtGapping=false -conll2008clf=false -iobj=true -name=false -posthon=true -deepenQP=true -qmod=true"
#Convert each file to dependency trees
java -jar ${PENNCONVERTER_JAR} ${ARGS} < training.mrg > training.conll
java -jar ${PENNCONVERTER_JAR} ${ARGS} < development.mrg > development.conll
java -jar ${PENNCONVERTER_JAR} ${ARGS} < test.mrg > test.conll

============================================
STEP 6: Run the final conversion script
============================================

java -cp fineconverter-0.2.jar tratz.parse.converter.ConllToFineGrain training.conll training.converted false
java -cp fineconverter-0.2.jar tratz.parse.converter.ConllToFineGrain development.conll training.converted false
java -cp fineconverter-0.2.jar tratz.parse.converter.ConllToFineGrain test.conll test.converted false

============================================
THE END
============================================

You should now have some files that look like this

1	The	_	DT	DT	_	2	det	_	_
2	man	_	NN	NN	_	3	subj	_	_
3	walked	_	VBD	VBD	_	0	ROOT	_	_
4	to	_	NN	NN	_	3	prep	_	_
5	the	_	DT	DT	_	6	det	_	_
6	store	_	NN	NN	_	4	pobj	_	_
7	.	_	.	.	_	3	punct	_	_
